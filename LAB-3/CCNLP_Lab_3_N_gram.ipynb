{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install and import necessary libraries"
      ],
      "metadata": {
        "id": "yTURFQiYvt4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR5SwzUa7gtL",
        "outputId": "ef1bd09a-444e-480f-ac75-dc78752c6ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "Aj6bwjr674A_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download necessary NLTK datasets"
      ],
      "metadata": {
        "id": "W1J1pZUcvtDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imXEoKgn75Qr",
        "outputId": "9ca8464f-07e3-43ef-809f-ab2ef70e46be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User input text"
      ],
      "metadata": {
        "id": "claezq4IvxrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter the text for N-gram modeling: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqiMcRgL79og",
        "outputId": "8ac9acb3-eea0-48f1-a6ac-90c475160279"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text for N-gram modeling: The sun is shining bright today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lowercasing (Normalization)"
      ],
      "metadata": {
        "id": "mbBeXSM7vz9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_text = text.lower()\n",
        "print(\"\\nNormalized Text:\\n\", normalized_text)"
      ],
      "metadata": {
        "id": "q4hLRjD78FrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932cc1af-5115-473e-ad8c-9a7bb00795a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Normalized Text:\n",
            " the sun is shining bright today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Tokenization"
      ],
      "metadata": {
        "id": "SJ0qj3xnv28A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(normalized_text)\n",
        "print(\"\\nSentence Tokenization:\\n\", sentences)"
      ],
      "metadata": {
        "id": "Cka2pq7p8Id3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c19ac9-fd11-41fa-925d-f4e8116d7cbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence Tokenization:\n",
            " ['the sun is shining bright today.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Tokenization"
      ],
      "metadata": {
        "id": "jNR2sawLv5HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(normalized_text)\n",
        "print(\"\\nWord Tokenization:\\n\", words)"
      ],
      "metadata": {
        "id": "Hu9TtaMD8KSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d3e357-012d-4cfe-bffb-cc6db00ea7e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Tokenization:\n",
            " ['the', 'sun', 'is', 'shining', 'bright', 'today', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove punctuation"
      ],
      "metadata": {
        "id": "oViUZ3Xlv95J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_no_punct = [word for word in words if word not in string.punctuation]\n",
        "print(\"\\nPunctuation Removal:\\n\", words_no_punct)"
      ],
      "metadata": {
        "id": "D_f-YEbd8MZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39aab966-5e0d-45a8-8974-67db94a1972a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Punctuation Removal:\n",
            " ['the', 'sun', 'is', 'shining', 'bright', 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopword Removal"
      ],
      "metadata": {
        "id": "4NxPL_qPv_sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words_no_punct if word not in stop_words]\n",
        "print(\"\\nStopword Removal:\\n\", filtered_words)"
      ],
      "metadata": {
        "id": "Tf9tqFDs8Nvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499a7e51-1639-4393-f50d-753e4887c6eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stopword Removal:\n",
            " ['sun', 'shining', 'bright', 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "PhTXYT2owCAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "print(\"\\nStemming:\\n\", stemmed_words)"
      ],
      "metadata": {
        "id": "DhCCwMTa8SCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b943b5-1592-4c7e-bd29-96331f0176c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming:\n",
            " ['sun', 'shine', 'bright', 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "fcXvYMNDwE7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "print(\"\\nLemmatization:\\n\", lemmatized_words)"
      ],
      "metadata": {
        "id": "RqgxLe-A8Tjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8598b187-99dc-49c7-844d-04042ab783e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lemmatization:\n",
            " ['sun', 'shining', 'bright', 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to generate n-grams"
      ],
      "metadata": {
        "id": "NDvzKu4jwFvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams(words, n):\n",
        "    return list(ngrams(words, n))"
      ],
      "metadata": {
        "id": "fmaYsRX58Vk8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Unigrams, Bigrams, and Trigrams"
      ],
      "metadata": {
        "id": "EPHO9mfIwIGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams = generate_ngrams(lemmatized_words, 1)\n",
        "print(\"\\nUnigrams:\\n\", unigrams)\n",
        "bigrams = generate_ngrams(lemmatized_words, 2)\n",
        "print(\"\\nBigrams:\\n\", bigrams)\n",
        "trigrams = generate_ngrams(lemmatized_words, 3)\n",
        "print(\"\\nTrigrams:\\n\", trigrams)"
      ],
      "metadata": {
        "id": "QR-MPNBn8aeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c64164-7057-41c8-fb86-cf5d39911bcb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unigrams:\n",
            " [('sun',), ('shining',), ('bright',), ('today',)]\n",
            "\n",
            "Bigrams:\n",
            " [('sun', 'shining'), ('shining', 'bright'), ('bright', 'today')]\n",
            "\n",
            "Trigrams:\n",
            " [('sun', 'shining', 'bright'), ('shining', 'bright', 'today')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert n-grams to string format for CountVectorizer"
      ],
      "metadata": {
        "id": "Sve9DfEQwL2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_text = [\" \".join(gram) for gram in unigrams]\n",
        "bigram_text = [\" \".join(gram) for gram in bigrams]\n",
        "trigram_text = [\" \".join(gram) for gram in trigrams]"
      ],
      "metadata": {
        "id": "_OKmJ5ko8iC_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize CountVectorizer for Bag of N-grams Model"
      ],
      "metadata": {
        "id": "Ewy7ZH29wNte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 3))  # Includes unigrams, bigrams, and trigrams"
      ],
      "metadata": {
        "id": "Q2CL6gas8kf-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit and transform the text"
      ],
      "metadata": {
        "id": "5_iZm2iTwRL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_matrix = vectorizer.fit_transform([\" \".join(lemmatized_words)])"
      ],
      "metadata": {
        "id": "n1_8MOS_8qoB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display Vocabulary (word-to-index mapping)"
      ],
      "metadata": {
        "id": "3xfw9l_ewS6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nVocabulary (Word to Index Mapping):\\n\", vectorizer.vocabulary_)"
      ],
      "metadata": {
        "id": "KlksZukA8sq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748b814a-0796-463e-d3e6-2ee72d7fe48b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary (Word to Index Mapping):\n",
            " {'sun': 5, 'shining': 2, 'bright': 0, 'today': 8, 'sun shining': 6, 'shining bright': 3, 'bright today': 1, 'sun shining bright': 7, 'shining bright today': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert sparse matrix to array"
      ],
      "metadata": {
        "id": "34etTNoowUu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_array = bow_matrix.toarray()"
      ],
      "metadata": {
        "id": "MKxKN8CQ8uNh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the BoW matrix"
      ],
      "metadata": {
        "id": "egDaXRbfwWfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBag of N-grams Matrix:\\n\", bow_array)"
      ],
      "metadata": {
        "id": "_wSUcGS-8vgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825210ab-4e03-448f-88f2-384e63de13c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of N-grams Matrix:\n",
            " [[1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert BoW matrix to DataFrame for better readability"
      ],
      "metadata": {
        "id": "fR4T1YnRwYRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_df = pd.DataFrame(bow_array, columns=vectorizer.get_feature_names_out())\n",
        "print(\"\\nBag of N-grams Representation:\\n\", bow_df)"
      ],
      "metadata": {
        "id": "MxVTTsdb8xJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b775defe-224d-4dec-88cd-5887aef8c12e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of N-grams Representation:\n",
            "    bright  bright today  shining  shining bright  shining bright today  sun  \\\n",
            "0       1             1        1               1                     1    1   \n",
            "\n",
            "   sun shining  sun shining bright  today  \n",
            "0            1                   1      1  \n"
          ]
        }
      ]
    }
  ]
}